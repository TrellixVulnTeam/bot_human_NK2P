{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.9 64-bit ('test': venv)",
   "display_name": "Python 3.6.9 64-bit ('test': venv)",
   "metadata": {
    "interpreter": {
     "hash": "3bd393dcd0585e776f775a92659209f43593a96296bc98d5242a7b2fd7ea15e7"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Predicción Bot-Humano\n",
    "### Dylan Javier Primera  T00045753\n",
    "\n",
    "### Romario Marimon Romero T00049321\n",
    "\n",
    "### Camilo Dario Bautista T00044509\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import sys\n",
    "import os\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from utils.text_analysis import TextAnalysis\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Language: es\nText Analysis: ['emoji', 'tagger', 'parser', 'stemmer', 'ner']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                              user_id  \\\n",
       "500  b8d7ac3042d45731e05ad00d56e0f8fe   \n",
       "501  9494c5001fbfb868f34a737f69e5ac62   \n",
       "502  b8528a4f489fded49709a7bb94d8e25f   \n",
       "503  de5c5734d56acc5da30f086f95646805   \n",
       "504  7960cc1f636243b5d8f22efeb0dec6e9   \n",
       "..                                ...   \n",
       "995  3531c7bb89c410da8592642c32a5e1f8   \n",
       "996  1b8ebbab6ebe891a66c18e3965bf3fb9   \n",
       "997  5631ded2b52f1692e77de2eb8d89c3d3   \n",
       "998  a5c1637f723544a64c4da1b8ddfb3dd8   \n",
       "999  981306abb546911d4162ed4ba7ebdec9   \n",
       "\n",
       "                                                tweets  is_human  \n",
       "500  ['RT @PoeticaAcciones: Hay que dedicarle más t...         1  \n",
       "501  ['@duxativa .Esta es la manera mas eficaz de e...         1  \n",
       "502  ['En Adventistas.cl: Amigos de Esperanza en Nu...         0  \n",
       "503  ['El PRD presentará mañana ante el Instituto F...         0  \n",
       "504  ['El Gobierno deniega el indulto a ‘los Albert...         0  \n",
       "..                                                 ...       ...  \n",
       "995  ['Como cuando tu ídolo no te deja en visto htt...         1  \n",
       "996  ['#ad Anbang retira de la puja por Starwood y ...         0  \n",
       "997  ['RT @accionlibertad: #RostrosDeLaInjusticia |...         1  \n",
       "998  ['RT @hurgamemoriaPE: Si tiene tan buena recom...         1  \n",
       "999  ['Me enamoré, no fue de ti, sino de tus mentir...         0  \n",
       "\n",
       "[500 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>tweets</th>\n      <th>is_human</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>500</th>\n      <td>b8d7ac3042d45731e05ad00d56e0f8fe</td>\n      <td>['RT @PoeticaAcciones: Hay que dedicarle más t...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>501</th>\n      <td>9494c5001fbfb868f34a737f69e5ac62</td>\n      <td>['@duxativa .Esta es la manera mas eficaz de e...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>502</th>\n      <td>b8528a4f489fded49709a7bb94d8e25f</td>\n      <td>['En Adventistas.cl: Amigos de Esperanza en Nu...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>503</th>\n      <td>de5c5734d56acc5da30f086f95646805</td>\n      <td>['El PRD presentará mañana ante el Instituto F...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>504</th>\n      <td>7960cc1f636243b5d8f22efeb0dec6e9</td>\n      <td>['El Gobierno deniega el indulto a ‘los Albert...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>3531c7bb89c410da8592642c32a5e1f8</td>\n      <td>['Como cuando tu ídolo no te deja en visto htt...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>1b8ebbab6ebe891a66c18e3965bf3fb9</td>\n      <td>['#ad Anbang retira de la puja por Starwood y ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>5631ded2b52f1692e77de2eb8d89c3d3</td>\n      <td>['RT @accionlibertad: #RostrosDeLaInjusticia |...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>a5c1637f723544a64c4da1b8ddfb3dd8</td>\n      <td>['RT @hurgamemoriaPE: Si tiene tan buena recom...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>981306abb546911d4162ed4ba7ebdec9</td>\n      <td>['Me enamoré, no fue de ti, sino de tus mentir...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 140
    }
   ],
   "source": [
    "ta = TextAnalysis('es')\n",
    "data_raw = pd.read_csv('data.csv')\n",
    "data_raw.iloc[500:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 3000/3000 [00:24<00:00, 122.68it/s]\n"
     ]
    }
   ],
   "source": [
    "setting = {'url': True, 'mention': True, 'emoji': True, 'hashtag': True, 'stopwords': False, 'relabel': True} \n",
    "list_sentences = []\n",
    "for row in tqdm(data_raw['tweets'].to_list()):\n",
    "    text = ta.clean_text(row, **setting)\n",
    "    #print('Text org: {0} \\nTex clean: {1}'.format(row, text))\n",
    "    list_sentences.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " x = list_sentences\n",
    " y = data_raw['is_human'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Replica y_train: [(0, 1500), (1, 1500)]\n"
     ]
    }
   ],
   "source": [
    " print('Replica y_train:', sorted(Counter(y).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Replica train: [(0, 1050), (1, 1050)], size 2100\nReplica test: [(0, 450), (1, 450)], size 900\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=8675309)\n",
    "print('Replica train: {0}, size {1}'.format(sorted(Counter(y_train).items()), len(y_train)))\n",
    "print('Replica test: {0}, size {1}'.format(sorted(Counter(y_test).items()), len(y_test)))"
   ]
  },
  {
   "source": [
    "# Feature in Bag of words"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(min_df=5, ngram_range=(1,3), max_features=5000, strip_accents='unicode', lowercase =True, analyzer='word')\n",
    "vec.fit(x_train)\n",
    "x_train = vec.transform(x_train)\n",
    "x_test = vec.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "'ok', 'olor', 'olor de', 'olor de unos', 'olvidar', 'olvido', 'on', 'on hashtag', 'once', 'onda', 'one', 'one person', 'online', 'only', 'onu', 'opcion', 'open', 'operacion', 'opinion', 'oportunidad', 'oportunidades', 'oposicion', 'or', 'orden', 'organizacion', 'orgullo', 'original', 'orlando', 'oro', 'ortega', 'os', 'oscar', 'otra', 'otra vez', 'otras', 'otro', 'otros', 'our', 'out', 'oye', 'pa', 'pablo', 'paciencia', 'pacientes', 'pacto', 'padre', 'padres', 'paga', 'pagar', 'pagina', 'pago', 'pais', 'pais url', 'paises', 'palabra', 'palabras', 'palacio', 'pan', 'pantalla', 'papa', 'papas', 'papel', 'par', 'par de', 'para', 'para el', 'para el de', 'para este', 'para evitar', 'para hacer', 'para hashtag', 'para hashtag de', 'para hoy', 'para hoy en', 'para ir', 'para la', 'para laborar', 'para laborar en', 'para las', 'para los', 'para mention', 'para mi', 'para no', 'para poder', 'para que', 'para que no', 'para ser', 'para su', 'para ti', 'para todos', 'para un', 'para una', 'para ver', 'paraguay', 'parcialmente', 'parcialmente nublado', 'parcialmente nublado hashtag', 'parcialmente nublado mas', 'parece', 'parece que', 'parecen', 'parecer', 'pareja', 'paris', 'parlamento', 'paro', 'parque', 'parte', 'parte de', 'parte de la', 'parte del', 'partes', 'participa', 'participacion', 'participar', 'partido', 'partido de', 'partidos', 'partir', 'partir de', 'pasa', 'pasado', 'pasan', 'pasando', 'pasar', 'pase', 'pasion', 'paso', 'pasos', 'past', 'past day', 'patria', 'paul', 'paz', 'pedido', 'pedir', 'pedro', 'pedro sanchez', 'pega', 'pelea', 'pelicula', 'peliculas', 'peligro', 'pelo', 'pelota', 'pena', 'pena nieto', 'penal', 'pensamiento', 'pensamientos', 'pensando', 'pensar', 'pensar que', 'pense', 'pensiones', 'people', 'peor', 'peor que', 'pequena', 'pequeno', 'pequenos', 'per', 'perder', 'perdida', 'perdido', 'perdiendo', 'perdio', 'perdiste', 'perdiste esta', 'perdiste esta en', 'perdon', 'perez', 'perfecta', 'perfecto', 'perfil', 'perfil laboral', 'perfil laboral envia', 'periodismo', 'periodista', 'periodistas', 'permite', 'pero', 'pero con', 'pero el', 'pero en', 'pero es', 'pero la', 'pero lo', 'pero me', 'pero no', 'pero que', 'pero se', 'pero si', 'perro', 'perro heroico', 'perro heroico salvo', 'perros', 'person', 'persona', 'persona que', 'personaje', 'personajes', 'personal', 'personas', 'personas en', 'personas que', 'peru', 'pesar', 'pesar de', 'pese', 'peso', 'pesos', 'petro', 'pfeiffer', 'pfeiffer url', 'php', 'pide', 'piden', 'pidio', 'pido', 'pie', 'piedra', 'piel', 'piensa', 'piensan', 'pienso', 'pierdas', 'pierde', 'pies', 'pinera', 'piso', 'piso si', 'piso si rebota', 'pizarra', 'pizarra del', 'placer', 'plan', 'plan de', 'planes', 'planeta', 'plata', 'plataforma', 'playa', 'plaza', 'plaza de', 'please', 'plena', 'pleno', 'pm', 'po', 'poblacion', 'pobre', 'pobres', 'pobreza', 'pocas', 'poco', 'poco de', 'pocos', 'podemos', 'poder', 'podes', 'podra', 'podria', 'podrian', 'poeta', 'point', 'polemica', 'policia', 'policias', 'politica', 'politicas', 'politico', 'politicos', 'pone', 'ponen', 'poner', 'pongo', 'popular', 'por', 'por ahi', 'por ciento', 'por ejemplo', 'por el', 'por eso', 'por favor', 'por fin', 'por hashtag', 'por la', 'por la senda', 'por las', 'por lo', 'por lo que', 'por los', 'por mas', 'por mention', 'por mention url', 'por mi', 'por no', 'por parte', 'por primera', 'por primera vez', 'por que', 'por que no', 'por san', 'por seguirme', 'por seguirme en', 'por ser', 'por si', 'por su', 'por sus', 'por ti', 'por todo', 'por tu', 'por un', 'por una', 'por url', 'porque', 'porque el', 'porque la', 'porque me', 'porque no', 'portugal', 'posible', 'post', 'potter', 'pp', 'pr', 'pre', 'precio', 'precio de', 'precio de la', 'precio del', 'precio del dolar', 'precio eur', 'precio eur emoji', 'precio eur precio', 'precios', 'precisa', 'precisan', 'prefiero', 'pregunta', 'preguntas', 'pregunto', 'premio', 'premios', 'prensa', 'prensa url', 'prepara', 'presencia', 'presenta', 'presentacion', 'presentacion de', 'presente', 'presento', 'presidencia', 'presidencial', 'presidenta', 'presidente', 'presidente de', 'presidente de la', 'presidente del', 'presion', 'preso', 'presos', 'presupuesto', 'preview', 'preview url', 'preview url unete', 'primer', 'primera', 'primera vez', 'primera vez en', 'primeras', 'primero', 'primeros', 'primeros rt', 'princesa', 'principal', 'principales', 'principio', 'prisa', 'prision', 'pro', 'problema', 'problemas', 'proceso', 'proceso de', 'produccion', 'producto', 'productos', 'profesional', 'profesionales', 'profesor', 'programa', 'programa de', 'programador', 'programas', 'pronto', 'propia', 'propio', 'propone', 'proposito', 'propuesta', 'propuestas', 'proteccion', 'protesta', 'protestas', 'provincia', 'proxima', 'proximo', 'proyecto', 'proyecto de', 'proyectos', 'prueba', 'pruebas', 'psoe', 'publica', 'publicado', 'publicas', 'publicidad', 'publico', 'publicos', 'pudo', 'pueblo', 'pueblos', 'pueda', 'puedan', 'puede', 'puede ser', 'pueden', 'puedes', 'puedo', 'puente', 'puerta', 'puertas', 'puerto', 'pues', 'puesto', 'puestos', 'puestos de', 'puigdemont', 'punta', 'punto', 'punto de', 'puntos', 'pura', 'puro', 'puso', 'puta', 'qu', 'que', 'que al', 'que alguien', 'que con', 'que cuando', 'que de', 'que dice', 'que dios', 'que el', 'que en', 'que era', 'que eres', 'que es', 'que es el', 'que es un', 'que esta', 'que estan', 'que estas', 'que este', 'que estoy', 'que fue', 'que ganas', 'que ha', 'que hace', 'que hacen', 'que hacer', 'que haces', 'que han', 'que hashtag', 'que hay', 'que hay que', 'que haya', 'que he', 'que hemos', 'que hoy', 'que la', 'que la gente', 'que las', 'que le', 'que les', 'que lo', 'que los', 'que mas', 'que me', 'que mention', 'que mi', 'que nadie', 'que ni', 'que no', 'que no es', 'que no me', 'que no se', 'que no te', 'que nos', 'que nunca', 'que pasa', 'que paso', 'que por', 'que puede', 'que quiere', 'que quiero', 'que rt', 'que rt mention', 'que se', 'que sea', 'que ser', 'que si', 'que siempre', 'que siguen', 'que siguen por', 'que solo', 'que son', 'que soy', 'que su', 'que tal', 'que te', 'que tenemos', 'que tengo', 'que tiene', 'que tienen', 'que tienes', 'que todo', 'que todos', 'que tu', 'que un', 'que una', 'que uno', 'que url', 'que url hashtag', 'que va', 'que van', 'que ver', 'que viene', 'que ya', 'que ya no', 'que yo', 'queda', 'quedan', 'quedar', 'quede', 'quedo', 'queremos', 'querer', 'queres', 'queria', 'querido', 'quien', 'quien es', 'quien no', 'quien se', 'quien te', 'quienes', 'quiera', 'quieras', 'quiere', 'quieren', 'quieres', 'quiero', 'quiero que', 'quimico', 'quisiera', 'quizas', 'radio', 'rafael', 'rajoy', 'ramon', 'ramos', 'rapido', 'raro', 'rato', 'razon', 'razones', 're', 'reaccion', 'real', 'real madrid', 'realidad', 'realizar', 'realizara', 'realizara follow', 'realizara follow automatico', 'realmente', 'rebota', 'rebota buscara', 'rebota buscara subira', 'rechazo', 'recibe', 'recibio', 'recibir', 'recibiras', 'recibiras reply', 'recibiras reply veces', 'recien', 'recomendado', 'recomiendo', 'reconoce', 'record', 'recordar', 'recuerda', 'recuerdo', 'recuerdos', 'recuperar', 'recursos', 'red', 'redes', 'redes sociales', 'referendum', 'reforma', 'reformas', 'refugiados', 'regalo', 'regalos', 'regimen', 'region', 'registra', 'registrado', 'registrado las', 'registrado las url', 'registro', 'regresa', 'regreso', 'reina', 'reino', 'reir', 'relacion', 'relaciones', 'remix', 'renta', 'renuncia', 'reply', 'reply veces', 'reply veces ni', 'reporte', 'reporte del', 'reporte del trafico', 'representa', 'republica', 'requiere', 'reserva', 'reservadas', 'reservadas emoji', 'reservadas emoji emoji', 'respecto', 'respeto', 'responde', 'responsabilidad', 'responsable', 'respuesta', 'resto', 'resulta', 'resultado', 'resultados', 'resumen', 'reto', 'retweet', 'retwitteado', 'reunion', 'revela', 'revolucion', 'rey', 'reyes', 'reyes magos', 'rica', 'rico', 'riesgo', 'riesgo de', 'rio', 'risa', 'rival', 'river', 'rivera', 'roberto', 'robo', 'rodriguez', 'roja', 'rojo', 'rompe', 'ropa', 'rosa', 'rostro', 'roto', 'rt', 'rt los', 'rt mention', 'rt mention ahora', 'rt mention al', 'rt mention aqui', 'rt mention asi', 'rt mention como', 'rt mention con', 'rt mention cuando', 'rt mention de', 'rt mention desde', 'rt mention el', 'rt mention emoji', 'rt mention en', 'rt mention es', 'rt mention esta', 'rt mention este', 'rt mention esto', 'rt mention estoy', 'rt mention feliz', 'rt mention gracias', 'rt mention hace', 'rt mention hashtag', 'rt mention hay', 'rt mention hola', 'rt mention hoy', 'rt mention la', 'rt mention las', 'rt mention lo', 'rt mention los', 'rt mention mas', 'rt mention me', 'rt mention mention', 'rt mention mi', 'rt mention nahuatl', 'rt mention no', 'rt mention nos', 'rt mention nunca', 'rt mention para', 'rt mention perro', 'rt mention por', 'rt mention que', 'rt mention quien', 'rt mention quiero', 'rt mention rt', 'rt mention se', 'rt mention si', 'rt mention solo', 'rt mention soy', 'rt mention te', 'rt mention the', 'rt mention todo', 'rt mention todos', 'rt mention tu', 'rt mention un', 'rt mention una', 'rt mention url', 'rt mention video', 'rt mention ya', 'rt mention yo', 'rt rt', 'rt te', 'rt to', 'rueda', 'rumbo', 'rusia', 'ruta', 'sabado', 'sabe', 'sabe que', 'sabemos', 'sabemos que', 'saben', 'saber', 'saber que', 'sabes', 'sabes de', 'sabes de alguien', 'sabes que', 'sabia', 'sabias', 'sabor', 'sabor de', 'sabor de unos', 'saca', 'sacar', 'saco', 'sala', 'sale', 'salen', 'salga', 'salida', 'salio', 'salir', 'salir de', 'salud', 'saludos', 'salvador', 'salvaje', 'salvaje ha', 'salvaje ha aparecido', 'salvar', 'salvo', 'salvo mujer', 'salvo mujer de', 'samsung', 'samsung galaxy', 'san', 'san juan', 'san juan registrado', 'sanchez', 'sanciones', 'sangre', 'santa', 'santiago', 'santo', 'santo domingo', 'santos', 'se', 'se busca', 'se busca desarrollador', 'se da', 'se debe', 'se encuentra', 'se esta', 'se fue', 'se ha', 'se hace', 'se han', 'se la', 'se le', 'se les', 'se llama', 'se lo', 'se me', 'se nos', 'se precisa', 'se puede', 'se pueden', 'se que', 'se realizara', 'se realizara follow', 'se si', 'se siente', 'se solicita', 'se te', 'se trata', 'se trata de', 'se url', 'se va', 'se van', 'se ve', 'se viene', 'sea', 'sean', 'seas', 'secretaria', 'secretario', 'secreto', 'sector', 'sede', 'seguidores', 'seguimos', 'seguir', 'seguir leyendo', 'seguir leyendo url', 'seguirme', 'seguirme en', 'seguirme en la', 'segun', 'segunda', 'segundo', 'segundos', 'seguridad', 'seguridad de', 'seguro', 'seis', 'seleccion', 'seleccion de', 'semana', 'semana de', 'semana url', 'semanas', 'senado', 'senador', 'senala', 'senda', 'senda trazada', 'senda trazada mention', 'senior', 'senor', 'senora', 'senores', 'sentencia', 'sentido', 'sentir', 'sentir de', 'sentir de unos', 'septiembre', 'ser', 'ser el', 'ser la', 'ser un', 'ser una', 'sera', 'sera el', 'seran', 'seres', 'sergio', 'seria', 'serie', 'series', 'serio', 'servicio', 'servicio de', 'servicios', 'sesion', 'set', 'sevilla', 'sevilla via', 'sevilla via mention', 'sexo', 'sexual', 'show', 'si', 'si cumples', 'si cumples con', 'si el', 'si en', 'si es', 'si hay', 'si la', 'si lo', 'si los', 'si me', 'si no', 'si que', 'si quieres', 'si rebota', 'si rebota buscara', 'si sabes', 'si sabes de', 'si se', 'si te', 'si tu', 'si url', 'sido', 'siempre', 'siendo', 'siente', 'siento', 'siete', 'siga', 'sigan', 'siglo', 'significa', 'sigo', 'sigue', 'sigue en', 'siguen', 'siguen por', 'siguen por la', 'sigues', 'siguiente', 'silencio', 'simon', 'simple', 'simplemente', 'sin', 'sin duda', 'sino', 'siquiera', 'siria', 'sirve', 'sismo', 'sismo de', 'sismo de con', 'sismo en', 'sistema', 'sistema de', 'sistemas', 'sitio', 'situacion', 'so', 'sobre', 'sobre el', 'sobre la', 'sobre las', 'sobre los', 'sobre todo', 'sobreviniente', 'sobreviniente nind', 'social', 'sociales', 'socialismo', 'sociedad', 'sol', 'sola', 'solamente', 'solar', 'soledad', 'solicita', 'solidaridad', 'solo', 'solo en', 'solo para', 'solo se', 'solo si', 'solo un', 'solucion', 'sombra', 'somos', 'son', 'son de', 'son las', 'son los', 'sonar', 'sonido', 'sonido de', 'sonido de unos', 'sonreir', 'sonrisa', 'sorteo', 'sos', 'soy', 'soy el', 'soy un', 'sr', 'sra', 'stack', 'star', 'start', 'stats', 'stats via', 'stats via url', 'su', 'su casa', 'su hijo', 'su nuevo', 'su primer', 'su vida', 'suarez', 'sube', 'subir', 'subira', 'sucede', 'sueldo', 'suelo', 'suena', 'sueno', 'suenos', 'suerte', 'suficiente', 'sufre', 'sufrir', 'suma', 'super', 'supera', 'superar', 'superior', 'supremo', 'supuesto', 'sur', 'sur de', 'sus', 'sus hijos', 'ta', 'tal', 'tal vez', 'talento', 'tambien', 'tambien se', 'tampoco', 'tan', 'tanta', 'tantas', 'tanto', 'tantos', 'tarde', 'tarde bueno', 'tarde bueno hashtag', 'tarde parcialmente', 'tarde parcialmente nublado', 'tarde tormentas', 'tarde tormentas electricas', 'tardes', 'tarea', 'te', 'te amo', 'te gusta', 'te hace', 'te lo', 'te mando', 'te quiero', 'teatro', 'techo', 'tecnica', 'tecnico', 'tecnologia', 'telefono', 'telegram', 'telegram url', 'telegram url hashtag', 'television', 'tema', 'tema de', 'temas', 'temporada', 'temporada de', 'temprano', 'tendra', 'tenemos', 'tenemos que', 'tener', 'tener un', 'tenes', 'tenga', 'tengan', 'tengas', 'tengo', 'tengo que', 'tenia', 'tenian', 'tenido', 'tercer', 'tercera', 'termina', 'terminar', 'termine', 'termino', 'terremoto', 'terreno', 'terrible', 'terror', 'terrorismo', 'th', 'thank', 'thank you', 'that', 'the', 'the best', 'the gamers', 'the gamers daily', 'the last', 'the past', 'the past day', 'the week', 'this', 'ti', 'tiempo', 'tiempo de', 'tiempo que', 'tiempos', 'tienda', 'tiene', 'tiene el', 'tiene la', 'tiene que', 'tiene un', 'tiene una', 'tienen', 'tienen que', 'tienen un', 'tienes', 'tienes que', 'tierra', 'time', 'times', 'tipico', 'tipo', 'tipo de', 'tipos', 'tiro', 'tiroteo', 'titular', 'titulo', 'to', 'to enter', 'to win', 'toca', 'toda', 'toda la', 'todas', 'todas las', 'todavia', 'todavia no', 'todo', 'todo el', 'todo el dia', 'todo el mundo', 'todo en', 'todo es', 'todo lo', 'todo lo que', 'todo un', 'todos', 'todos los', 'todos los companeros', 'todos los dias', 'todos los que', 'toma', 'toman', 'tomar', 'tomas', 'tomo', 'top', 'tormentas', 'tormentas electricas', 'tormentas electricas hashtag', 'torneo', 'torres', 'total', 'totalmente', 'tour', 'trabaja', 'trabajadores', 'trabajando', 'trabajar', 'trabajo', 'trabajo de', 'trabajo url', 'trae', 'trafico', 'trafico hashtag', 'trafico hashtag hashtag', 'trailer', 'transito', 'transporte', 'tras', 'tras el', 'tras la', 'trata', 'trata de', 'tratamiento', 'tratar', 'traves', 'traves de', 'trazada', 'trazada mention', 'trazada mention gracias', 'tremendo', 'tren', 'tres', 'tribunal', 'triste', 'tristeza', 'triunfo', 'trump', 'tts', 'tts espana', 'tts espana hashtag', 'tu', 'tu cv', 'tu no', 'tu vida', 'tuit', 'tuits', 'turismo', 'turquia', 'tus', 'tuve', 'tuvo', 'tuya', 'tuyo', 'tv', 'tweet', 'tweets', 'twitter', 'ud', 'ud emoji', 'ud emoji emoji', 'ud url', 'ue', 'uf', 'ufd', 'ufd hashtag', 'ufd hashtag hashtag', 'ufd ufd', 'ufd ufd hashtag', 'ufd ufd ufd', 'ufe', 'ultima', 'ultimas', 'ultimas hashtag', 'ultimas hashtag url', 'ultimo', 'ultimos', 'un', 'un abrazo', 'un amigo', 'un ano', 'un atraco', 'un atraco url', 'un buen', 'un de', 'un dia', 'un en', 'un gran', 'un grupo', 'un grupo de', 'un hashtag', 'un hombre', 'un libro', 'un mes', 'un nino', 'un nuevo', 'un pais', 'un par', 'un par de', 'un partido', 'un poco', 'un poco de', 'un rt', 'un solo', 'un url', 'un video', 'una', 'una buena', 'una cosa', 'una de', 'una de las', 'una foto', 'una gran', 'una lista', 'una mujer', 'una nueva', 'una persona', 'una semana', 'una sola', 'una vez', 'una vida', 'unas', 'unete', 'unete mention', 'unete mention descargar', 'unete mention estreno', 'unete mention url', 'unete mention video', 'unfollowed', 'unfollowed me', 'unfollowers', 'unica', 'unico', 'unico que', 'unidad', 'unido', 'unidos', 'union', 'universidad', 'universo', 'uno', 'uno de', 'uno de los', 'unos', 'up', 'ur', 'urgente', 'uribe', 'url', 'url aplicaciones', 'url aplicaciones noticias', 'url asi', 'url by', 'url by hashtag', 'url como', 'url con', 'url cuando', 'url de', 'url el', 'url el precio', 'url emoji', 'url emoji emoji', 'url en', 'url es', 'url esta', 'url este', 'url feliz', 'url gracias', 'url gracias mention', 'url hashtag', 'url hashtag apartamento', 'url hashtag asi', 'url hashtag casa', 'url hashtag como', 'url hashtag departamento', 'url hashtag el', 'url hashtag en', 'url hashtag hashtag', 'url hashtag inf', 'url hashtag la', 'url hashtag las', 'url hashtag los', 'url hashtag mar', 'url hashtag mas', 'url hashtag mention', 'url hashtag muere', 'url hashtag que', 'url hashtag rt', 'url hashtag se', 'url hashtag un', 'url hashtag una', 'url hashtag url', 'url hay', 'url hoy', 'url https', 'url https rt', 'url la', 'url la frase', 'url las', 'url lo', 'url los', 'url mas', 'url mas en', 'url me', 'url mention', 'url mention el', 'url mention emoji', 'url mention en', 'url mention hashtag', 'url mention la', 'url mention mention', 'url mention no', 'url mention rt', 'url mention url', 'url mi', 'url no', 'url no me', 'url para', 'url por', 'url por mention', 'url que', 'url reporte', 'url reporte del', 'url rt', 'url rt mention', 'url se', 'url se precisa', 'url si', 'url si cumples', 'url sismo', 'url sismo de', 'url te', 'url the', 'url un', 'url una', 'url unete', 'url unete mention', 'url url', 'url url el', 'url url hashtag', 'url url la', 'url url mention', 'url url rt', 'url url sismo', 'url url url', 'url via', 'url via mention', 'url video', 'url ya', 'url yo', 'uruguay', 'us', 'usa', 'usar', 'usgs', 'usgs hashtag', 'usgs hashtag utc', 'uso', 'uso de', 'usted', 'ustedes', 'usuarios', 'utc', 'utc url', 'utc url hashtag', 'uu', 'va', 'va para', 'va para hashtag', 'va ser', 'vacaciones', 'vacio', 'vale', 'valencia', 'valle', 'valor', 'valores', 'vamos', 'van', 'varias', 'varios', 'vas', 'vaya', 'vayan', 've', 'vea', 'vean', 'veces', 'veces ni', 'veces ni se', 'vecinos', 'vehiculos', 'vemos', 'ven', 'vende', 'vender', 'venezolana', 'venezolano', 'venezolanos', 'venezuela', 'venezuela url', 'venga', 'vengan', 'vengan degollando', 'vengan degollando mention', 'venir', 'venta', 'venta en', 'venta nalberdi', 'venta nalberdi ncompra', 'venta ncambios', 'venta ncambios chaco', 'venta nmaxicambios', 'venta nmaxicambios ncompra', 'ventas', 'veo', 'ver', 'ver como', 'ver el', 'ver la', 'ver si', 'verano', 'verdad', 'verdadera', 'verdadero', 'verde', 'verguenza', 'verlo', 'version', 'verte', 'ves', 'vestido', 'vez', 'vez de', 'vez en', 'vez mas', 'vez que', 'vi', 'via', 'via mention', 'via mention el', 'via mention hashtag', 'via mention mention', 'via mention rt', 'via mention url', 'via url', 'viajar', 'viaje', 'victima', 'victimas', 'victimas de', 'victor', 'victoria', 'vida', 'vida de', 'vida es', 'vida no', 'vida url', 'vidas', 'video', 'video de', 'video el', 'video oficial', 'video oficial url', 'video url', 'video url unete', 'videos', 'vieja', 'viejo', 'viendo', 'viene', 'vienen', 'viento', 'viernes', 'villa', 'vino', 'vio', 'violencia', 'violeta', 'visita', 'vista', 'vistazo', 'viste', 'visto', 'viva', 'vive', 'viven', 'vivienda', 'vivir', 'vivo', 'vivo en', 'voluntad', 'volver', 'volvio', 'vos', 'vos todos', 'vos todos los', 'vosotros', 'vota', 'votar', 'voto', 'votos', 'vox', 'voy', 'voz', 'vs', 'vuelta', 'vuelto', 'vuelve', 'vuelven', 'want', 'was', 'washington', 'we', 'web', 'week', 'what', 'whatsapp', 'when', 'who', 'will', 'william', 'win', 'windows', 'winner', 'with', 'word', 'word of', 'word of the', 'world', 'worldwide', 'worldwide emoji', 'xa', 'xa url', 'xd', 'xq', 'ya', 'ya en', 'ya es', 'ya esta', 'ya lo', 'ya me', 'ya no', 'ya que', 'ya se', 'ya te', 'ya tiene', 'yankee', 'yo', 'yo creo', 'yo me', 'yo no', 'yo quiero', 'yo soy', 'yo tambien', 'yo te', 'york', 'you', 'your', 'youtube', 'zona', 'zona de', 'ريتويت', 'لزيادة', 'をフォローしてくたさい', '相互', '相互 相互フォロー', '相互フォロー']\n"
     ]
    }
   ],
   "source": [
    "print(vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n ...\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train.toarray())"
   ]
  },
  {
   "source": [
    "# Random Over Sampling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RandomOverSampler train: [(0, 1050), (1, 1050)]\nRandomOverSampler test: [(0, 450), (1, 450)]\n"
     ]
    }
   ],
   "source": [
    "ros = RandomOverSampler(random_state=1000)\n",
    "x_train, y_train = ros.fit_resample(x_train, y_train)\n",
    "x_test, y_test = ros.fit_resample(x_test, y_test)\n",
    "print('RandomOverSampler train:', sorted(Counter(y_train).items()))\n",
    "print('RandomOverSampler test:', sorted(Counter(y_test).items()))"
   ]
  },
  {
   "source": [
    "## Logistic Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(C=10, solver='lbfgs', multi_class='multinomial',max_iter=1000) \n",
    "classifier.fit(x_train, y_train)\n",
    "y_pred = classifier.predict(x_test)"
   ]
  },
  {
   "source": [
    "# Metrics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nConfusion Matrix\n[[414  36]\n [ 12 438]]\n"
     ]
    }
   ],
   "source": [
    "print('\\nConfusion Matrix')\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nClasification Report\n              precision    recall  f1-score   support\n\n           0       0.97      0.92      0.95       450\n           1       0.92      0.97      0.95       450\n\n    accuracy                           0.95       900\n   macro avg       0.95      0.95      0.95       900\nweighted avg       0.95      0.95      0.95       900\n\n"
     ]
    }
   ],
   "source": [
    "print('\\nClasification Report')\n",
    "print(classification_report(y_test, y_pred))\n",
    "cv_score = np.mean(cross_val_score(classifier, x_train,y_train, cv=3, scoring='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 95.0%\nRecall: 95.0%\nPrecision: 95.0%\nF1: 95.0%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred) #% de veces que el modelo acerta\n",
    "recall = recall_score(y_test, y_pred, average='macro')# el modelo es capar de identificar un 95%\n",
    "precision = precision_score(y_test, y_pred, average='weighted') # el modelo se equivoca un 5% en las veces que hace la predicción \n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print('Accuracy: {}%'.format(round(accuracy, 2)*100))\n",
    "print('Recall: {}%'.format(round(recall, 2)*100))\n",
    "print('Precision: {}%'.format(round(precision, 2)*100))\n",
    "print('F1: {}%'.format(round(f1, 2)*100))"
   ]
  },
  {
   "source": [
    "# Another prediction to compare results \n",
    "### Random Forest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## other way to get Bag of words"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=5000, min_df=5, max_df=0.7)\n",
    "\n",
    "X = vectorizer.fit_transform(data_raw['tweets']).toarray()"
   ]
  },
  {
   "source": [
    "## To convert values obtained using the bag of words model into TFIDF values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfconverter = TfidfTransformer()\n",
    "X = tfidfconverter.fit_transform(X).toarray()"
   ]
  },
  {
   "source": [
    "## Training sets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "source": [
    "# random Forest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "classifier.fit(X_train2, y_train2) \n",
    "y_pred2 = classifier.predict(X_test2)"
   ]
  },
  {
   "source": [
    "## Second Metrics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nConfution matrix : \n [[374  68]\n [ 13 445]]\n---------------------------------------------------------------\n\n\nClasification report\n  \n               precision    recall  f1-score   support\n\n           0       0.97      0.85      0.90       442\n           1       0.87      0.97      0.92       458\n\n    accuracy                           0.91       900\n   macro avg       0.92      0.91      0.91       900\nweighted avg       0.92      0.91      0.91       900\n\n"
     ]
    }
   ],
   "source": [
    "print('\\nConfution matrix : \\n',confusion_matrix(y_test2,y_pred2))\n",
    "print('---------------------------------------------------------------')\n",
    "print('\\n\\nClasification report\\n ','\\n',classification_report(y_test2,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 91.0%\nRecall: 91.0%\nPrecision: 92.0%\nF1: 91.0%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test2, y_pred2) #% de veces que el modelo acerta\n",
    "recall = recall_score(y_test2, y_pred2, average='macro')# el modelo es capar de identificar un 95%\n",
    "precision = precision_score(y_test2, y_pred2, average='weighted') # el modelo se equivoca un 5% en las veces que hace la predicción \n",
    "f1 = f1_score(y_test2, y_pred2, average='weighted')\n",
    "print('Accuracy: {}%'.format(round(accuracy, 2)*100))\n",
    "print('Recall: {}%'.format(round(recall, 2)*100))\n",
    "print('Precision: {}%'.format(round(precision, 2)*100))\n",
    "print('F1: {}%'.format(round(f1, 2)*100))"
   ]
  },
  {
   "source": [
    "# Conclusión\n",
    "Mediante los dos algoritmos de clasificación binaria para para la predicción de la procedencia de los tweets, es decir si pertenecía a un humano o a un bot, logramos confirmar que la teoria de que la Logistic Regression arroja resultados de mayor eficiencia para clasificaciones binarias que nuestro segundo algoritmo, el cual fue Random Forest, ya que las metricas obtenidas por el primer algoritmo en general muestran mejores resultados en comparación con el segundo algoritmo en aproximadamente un 4%."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}